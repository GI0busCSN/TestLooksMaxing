import{_ as S,i as g,c as P,j as _,r as h,a as T,o as k,b as r,d as l,w as u,e as m,t as f,F as E}from"./index-DwEWR1IX.js";const I='\nTask: Perform a LooksMaxing facial analysis using two photos — (1) front-facing and (2) side profile.\n\n⚠️ Must always return valid JSON (array with one object).  \nNo text, comments, or explanations outside JSON.\n\n---\n\n### STEP 0. Error System\n\nAlways return errors as:\n{\n  "Error": {\n    "Reason": "<text>",\n    "Type": "<wrongPic|ServerError>"\n  }\n}\n\n**Error Types:**\n\n- **ServerError** — no photos or invalid links.  \n  Example: "No photos uploaded or links are unreachable."\n\n- **wrongPic** — any issue with content, angle, or identity.  \n  Examples:\n  - "The two photos show different people."\n  - "Front photo is not frontal — head turned or tilted."\n  - "Profile photo not side view — too much face visible."\n  - "Face unclear due to poor lighting."\n  - "This isn’t a human — looks like you photographed your keyboard. Let’s get back to business."\n\n---\n\n### STEP 1. Photo Validation\n\nCheck both images:\n- **Front (ID 0):** face looks straight at the camera, neutral expression, evenly lit, sharp, full face visible.\n- **Profile (ID 1):** clear side view (forehead, nose, chin visible), head not turned toward camera, even lighting, sharp.\n\nIf either fails — return **Type: "wrongPic"** with specific reason.\n\nMust also verify:\n- Both photos are of **the same person**.  \n  If not — return Type: "wrongPic" with Reason: "Different people detected on photos."\n- First = front view, second = profile view.  \n  If wrong order — return Type: "wrongPic" with Reason: "First must be frontal, second must be profile."\n\n---\n\n### STEP 2. Facial Analysis (if both valid)\n\n1. "gender": user-provided or "unspecified".\n2. Evaluate: forehead, eyes, nose, lips, cheeks, jawline, chin, skin, hair.\n3. For each feature:\n   - "trait": short descriptive text\n   - "score": 0–10 (**underestimate by 1–2 points**)\n4. Compute "averageScore" (1 decimal).\n5. Recommend "typeOfTraining":\n   - gymmaxxing\n   - skincaremaxxing\n   - stylemaxxing\n   - mewing\n   - surgerymaxxing  \n   with a short "reason".\n\n---\n\n### STEP 3. Scoring Scale\n\n0 – unreadable/extreme deformity  \n1–2 – very poor, major asymmetry  \n3–4 – below average, visible flaws  \n5 – average  \n6–7 – good, minor flaws  \n8–9 – very good  \n10 – ideal\n\n---\n\n### STEP 4. Final JSON (no example values)\n\n[\n  {\n    "gender": "<string or \'unspecified\'>",\n    "features": {\n      "forehead": { "trait": "<string>", "score": <0-10> },\n      "eyes": { "trait": "<string>", "score": <0-10> },\n      "nose": { "trait": "<string>", "score": <0-10> },\n      "lips": { "trait": "<string>", "score": <0-10> },\n      "cheeks": { "trait": "<string>", "score": <0-10> },\n      "jawline": { "trait": "<string>", "score": <0-10> },\n      "chin": { "trait": "<string>", "score": <0-10> },\n      "skin": { "trait": "<string>", "score": <0-10> },\n      "hair": { "trait": "<string>", "score": <0-10> }\n    },\n    "averageScore": <number>,\n    "typeOfTraining": {\n      "TrainingId": "<gymmaxxing|skincaremaxxing|stylemaxxing|mewing|surgerymaxxing>",\n      "reason": "<short text>"\n    }\n  }\n]\n',M={class:"wrapper"},R={class:"cards"},F={class:"card front"},N={class:"scan-container","aria-hidden":"false"},O="https://text.pollinations.ai/openai",j="25cd5cd35f3e85431a2f1e96904d24f7",B="https://raw.githubusercontent.com/GI0busCSN/LooksMax-Articles/refs/heads/main/MaxPromt.txt",D={__name:"Results",props:["data"],setup(d){const c=d,n=g(),i=g("Scanning"),y=P(()=>i.value);setInterval(()=>{!n.value!=="Scanning"&&(i.value+=".",i.value.length>11&&(i.value="Scanning"))},500);const v="https://api.imgbb.com/1/upload?key=".concat(j);async function p(e){const t=new FormData,a=e.replace(/^data:image\/(png|jpeg|jpg);base64,/,"");t.append("image",a);try{const o=await(await fetch(v,{method:"POST",body:t})).json();if(o.success&&o.data&&o.data.url)return o.data.url;throw new Error("Image upload failed")}catch(s){throw console.error("Image upload error:",s),s}}const w=()=>fetch(B).then(e=>{if(!e.ok)throw new Error("Failed to fetch prompt");return e.text()}).then(e=>(console.log("Fetched prompt:",e),e)).catch(e=>(console.error("Prompt fetch error:",e),I)),x=async(e,t)=>({model:"openai",messages:[{role:"system",content:await w()},{role:"user",content:JSON.stringify({frontPhoto:e,profilePhoto:t})}],temperature:1,stream:!1,reasoning_effort:"high"});async function b(){n.value="Scanning";try{const[e,t]=await Promise.all([p(c.data.front),p(c.data.side)]),a=await x(e,t);console.log("Sending request with body:",a);const o=await(await fetch(O,{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify(a)})).json();o.choices&&o.choices.length>0?(console.log("Response content:",o.choices[0].message.content),n.value="Done"):(console.log("No content returned"),n.value="Error")}catch(e){n.value="Error",console.error("Request error:",e)}}return _(()=>{b()}),(e,t)=>{const a=h("MaxText"),s=h("MaxImage");return k(),T(E,null,[r("div",M,[l(a,{class:"large center"},{default:u(()=>[m(f(y.value),1)]),_:1}),r("div",R,[r("div",F,[r("div",N,[l(s,{img:d.data.front,borderRadius:25},null,8,["img"]),t[0]||(t[0]=r("div",{class:"scan-overlay","aria-hidden":"true"},[r("div",{class:"scan-line",role:"presentation"}),r("div",{class:"scan-grid",role:"presentation"}),r("div",{class:"scan-glow",role:"presentation"})],-1))])])])]),l(a,null,{default:u(()=>[m(f(c.data.front),1)]),_:1})],64)}}},C=S(D,[["__scopeId","data-v-f8b79805"]]);export{C as default};
